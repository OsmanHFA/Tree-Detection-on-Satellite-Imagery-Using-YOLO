{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40f5c3cc-1fce-43be-9901-0854df2186f3",
   "metadata": {},
   "source": [
    "# Train YOLOv8 with Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "683231fa-c1b1-48e7-bbf3-188d09e976e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import display, Image\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c2f29c-c9e8-45e6-ad5a-4ca0e5c11526",
   "metadata": {},
   "source": [
    "# Custom Dataset Class to Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42b80237-6afb-4a39-8678-eb9f72b1b4b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.images = [img for img in os.listdir(image_dir) if img.endswith('.jpg')]\n",
    "        self.images.sort()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        label_path = os.path.join(self.label_dir, img_name.replace('.jpg', '.txt'))\n",
    "        boxes = pd.read_csv(label_path, header=None, delim_whitespace=True).values\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, bboxes=boxes)\n",
    "            image = augmented['image']\n",
    "            boxes = augmented['bboxes']\n",
    "\n",
    "        return image, boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fa4ee9-aca0-4730-9658-3a2dfa26bab6",
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ab2842d-70c5-421b-8707-1b9aa8a4621b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_transforms():\n",
    "    return A.Compose([\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Flip(p=0.5),\n",
    "        A.Transpose(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.HueSaturationValue(p=0.5),\n",
    "        A.GaussianBlur(p=0.3),\n",
    "        A.GaussNoise(p=0.3),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomSizedBBoxSafeCrop(640, 640, p=0.5),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params=A.BboxParams(format='yolo', label_fields=[]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc87a1b2-d4dd-4134-b70a-0f3a95825006",
   "metadata": {},
   "source": [
    "# Training with Augmented Data (on-the-fly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5070a292-1a99-4014-b927-1ffe0a068f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_yolo(model_name, data_path, total_epochs, img_size):\n",
    "    # Load model\n",
    "    model = YOLO(model_name)\n",
    "\n",
    "    # creating datasets and loaders\n",
    "    train_transforms = get_transforms()\n",
    "    train_dataset = CustomDataset('/home/jupyter/ee_tree_counting/Data/Dataset 348-17-15/train', \n",
    "                                  '/home/jupyter/ee_tree_counting/Data/Dataset 348-17-15/train/labels', \n",
    "                                  transform=train_transforms)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "\n",
    "    val_transforms = get_transforms()\n",
    "    val_dataset = CustomDataset('/home/jupyter/ee_tree_counting/Data/Dataset 348-17-15/valid/images', \n",
    "                                '/home/jupyter/ee_tree_counting/Data/Dataset 348-17-15/valid/labels', \n",
    "                                transform=val_transforms)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Training\n",
    "    results = model.train(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=total_epochs,\n",
    "        imgsz=img_size,\n",
    "        save=True,\n",
    "        plots=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "247a52c0-6b81-4a91-9fb9-db8926bb23db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Train YOLOv8 model.\")\n",
    "    parser.add_argument('--model', type=str, default='yolov8s.pt', help='Pre-trained model path')\n",
    "    parser.add_argument('--data', type=str, required=True, help='Path to dataset')\n",
    "    parser.add_argument('--epochs', type=int, default=25, help='Number of epochs to train')\n",
    "    parser.add_argument('--img_size', type=int, default=800, help='Image size for training')\n",
    "    return parser.parse_args()\n",
    "\n",
    "def parse_args_notebook():\n",
    "    args = argparse.Namespace(\n",
    "        model='yolov8s.pt',\n",
    "        data='/home/jupyter/ee_tree_counting/Data/Dataset 348-17-15/data.yaml',\n",
    "        epochs=100,\n",
    "        img_size=640,\n",
    "        batch=16,\n",
    "        save=True,\n",
    "        plots=True\n",
    "    )\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96997563-96a2-4e0d-b4c5-a38a0eaa76c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m args \u001b[38;5;241m=\u001b[39m parse_args_notebook()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_yolo\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 10\u001b[0m, in \u001b[0;36mtrain_yolo\u001b[0;34m(model_name, data_path, total_epochs, img_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m train_transforms \u001b[38;5;241m=\u001b[39m get_transforms()\n\u001b[1;32m      7\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m CustomDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/jupyter/ee_tree_counting/Data/Dataset 348-17-15/train\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      8\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/jupyter/ee_tree_counting/Data/Dataset 348-17-15/train/labels\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      9\u001b[0m                               transform\u001b[38;5;241m=\u001b[39mtrain_transforms)\n\u001b[0;32m---> 10\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m val_transforms \u001b[38;5;241m=\u001b[39m get_transforms()\n\u001b[1;32m     13\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m CustomDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/jupyter/ee_tree_counting/Data/Dataset 348-17-15/valid/images\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     14\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/jupyter/ee_tree_counting/Data/Dataset 348-17-15/valid/labels\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     15\u001b[0m                             transform\u001b[38;5;241m=\u001b[39mval_transforms)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:344\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 344\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    346\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/sampler.py:107\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement))\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue, but got num_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples))\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "args = parse_args_notebook()\n",
    "train_yolo(args.model, args.data, args.epochs, args.img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476a2c63-f012-4094-a106-6ba2447f91ff",
   "metadata": {},
   "source": [
    "# Data Augmentation: Geometric Augmentation Mainly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4388d3a6-4379-400a-a77d-7fbc94b640bb",
   "metadata": {},
   "source": [
    "### Plan: See if geometric augmentations improve anything, then build big dataset. Do augmentations and add that as further training. Then integrate annotated satellite images with seasonal augmentation, enhanced contrast etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98642371-7433-40f0-80d6-2a43db454159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu121.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu121:m122"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
